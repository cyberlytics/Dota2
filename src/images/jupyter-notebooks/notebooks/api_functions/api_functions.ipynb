{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../Setup.ipynb\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bdcc.database.connection import database_connector as connector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_match(match):\n",
    "    \"\"\"\n",
    "    Function to create entries in the database.\n",
    "    params: *match: dict of match data\n",
    "    return: HTTP-Status Code\n",
    "    \"\"\"\n",
    "    http_status = 200   \n",
    "    db_con = connector.DatabaseConnector() # connect to database\n",
    "    db_con.connect()\n",
    "\n",
    "    match_found = False\n",
    "    for entry in db_con.get(id=match['match_id']):\n",
    "        if entry:\n",
    "            match_found = True\n",
    "\n",
    "    if not match_found:\n",
    "        http_status = 201\n",
    "        db_con.create(match) # create new entry in database\n",
    "    else:\n",
    "        http_status = 409\n",
    "\n",
    "    db_con.disconnect()\n",
    "\n",
    "    return http_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_match(match_id):\n",
    "    \"\"\"\n",
    "    Function to delete entries in the database.\n",
    "    params: *match_id: id of the match to be deleted\n",
    "    \"\"\"\n",
    "    http_status = 200\n",
    "    db_con = connector.DatabaseConnector()\n",
    "    db_con.connect()\n",
    "\n",
    "    # Überprüfung, ob zu löschendes Match in Datenbank existiert\n",
    "    matches = list(db_con.get())\n",
    "    if any(match['match_id'] == match_id for match in matches):\n",
    "        http_status = 205\n",
    "        db_con.remove(match_id)\n",
    "    else:\n",
    "        http_status = 204\n",
    "    \n",
    "    db_con.disconnect()\n",
    "    return http_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe_no_kda(matches):\n",
    "    \"\"\"\n",
    "    Function to build dataframe for model no_kda.\n",
    "    params: *matches: match data\n",
    "    \"\"\"\n",
    "    ttl_pings_list = []\n",
    "    \n",
    "    for j in range(len(matches)):\n",
    "        total_pings_win = 0\n",
    "        total_pings_loss = 0\n",
    "        for i in range(len(matches[j]['players'])):\n",
    "            if matches[j]['players'][i]['win'] == True:\n",
    "                total_pings_win += matches[j]['players'][i]['pings']\n",
    "            else:\n",
    "                total_pings_loss += matches[j]['players'][i]['pings']\n",
    "        ttl_pings_list.append([total_pings_win, True])\n",
    "        ttl_pings_list.append([total_pings_loss, False])\n",
    "    dataframe = pd.DataFrame(ttl_pings_list, columns =['ttlPings', 'win'])\n",
    "    dataframe = dataframe.dropna() # just to be sure\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe_kda(matches):\n",
    "    \"\"\"\n",
    "    Function to build dataframe for model kda.\n",
    "    params: *matches: match data\n",
    "    \"\"\"\n",
    "    filter_keys = ['assists', 'deaths', 'kills', 'pings', 'win']\n",
    "    player_kda_list = []\n",
    "    \n",
    "    for j in range(len(matches)):\n",
    "        for i in range(len(matches[j]['players'])):\n",
    "            player_kda_list.append({key:value for key, value in matches[j]['players'][i].items() if key in filter_keys})\n",
    "\n",
    "    dataframe_kda = pd.DataFrame(player_kda_list)\n",
    "    dataframe_kda = dataframe_kda.dropna() # just to be sure\n",
    "    \n",
    "    return dataframe_kda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name):\r\n",
    "    \"\"\"\r\n",
    "    Function to train models from database.\r\n",
    "    params: *model_name: name of the model to be trained\r\n",
    "    \"\"\"\r\n",
    "    http_status = 200\r\n",
    "\r\n",
    "    if model_name != \"kda\" and model_name != \"no_kda\":\r\n",
    "        http_status = 400\r\n",
    "    else:\r\n",
    "        db_con = connector.DatabaseConnector()\r\n",
    "        db_con.connect()\r\n",
    "    \r\n",
    "        matches = list(db_con.get())\r\n",
    "        db_con.disconnect()\r\n",
    "    \r\n",
    "        # User Story 1, model no_kda\r\n",
    "        if model_name == \"no_kda\":\r\n",
    "            dataframe = build_dataframe_no_kda(matches)\r\n",
    "        \r\n",
    "            # Prepare features\r\n",
    "            y_data_labels = dataframe['win']\r\n",
    "            x_data_features = dataframe['ttlPings']\r\n",
    "            # Reshape to 1-D array(column-vector)\r\n",
    "            x_data_features = np.array(x_data_features).reshape(-1,1)\r\n",
    "        \r\n",
    "        # User Story 2/3, model kda\r\n",
    "        else:\r\n",
    "            dataframe_kda = build_dataframe_kda(matches)\r\n",
    "            \r\n",
    "            # Prepare features\r\n",
    "            y_data_labels = dataframe_kda['win']\r\n",
    "            x_data_features = dataframe_kda.drop(['win'], axis=1)\r\n",
    "        \r\n",
    "        # Train model\r\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_data_features, y_data_labels, test_size=0.2)\r\n",
    "        mlp_classifier = MLPClassifier(max_iter=1000).fit(x_train, y_train)\r\n",
    "    \r\n",
    "        # save model to database, depending on name\r\n",
    "        if model_name == \"no_kda\":\r\n",
    "            connector.save_model(mlp_classifier, \"no_kda\")\r\n",
    "        else:\r\n",
    "            connector.save_model(mlp_classifier, \"kda\")\r\n",
    "    \r\n",
    "    return http_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary_prediction_results(prediction: np.ndarray, prediction_proba: np.ndarray, score: float) -> dict:\n",
    "    \"\"\"\n",
    "    Function to create the return dictionary in JSON format for prediction results.\n",
    "    params: *prediction: numpy array of predictions\n",
    "            *prediction_proba: numpy of probabilties of the predictions\n",
    "            *score: float of prediction score\n",
    "    return: JSON object of prediction results\n",
    "    \"\"\"\n",
    "    prediction = prediction.tolist()\n",
    "    prediction_proba = prediction_proba.tolist()\n",
    "    result_list = []\n",
    "    for i in range(len(prediction)):\n",
    "        result_list.append({\"predict\": prediction[i], \"predict_proba\": prediction_proba[i]})\n",
    "    return_dict = {\"score\": score, \"results\": result_list}\n",
    "    return json.dumps(return_dict) #convert to correct JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_name, matches):\n",
    "    \"\"\"\n",
    "    Function to predict dataset with model.\n",
    "    params: *model_name: name of the model to predict with\n",
    "    params: *matches: match data to predict\n",
    "    \"\"\"\n",
    "    http_status = 200\n",
    "    prediction_results = \"\"\n",
    "\n",
    "    if model_name != \"kda\" and model_name != \"no_kda\":\n",
    "        http_status = 400\n",
    "    else:\n",
    "        # User Story 1, model no_kda for prediction\n",
    "        if model_name == \"no_kda\":\n",
    "            # Load model\n",
    "            mlp_classifier = connector.load_model(\"no_kda\")\n",
    "            \n",
    "            dataframe = build_dataframe_no_kda(list(matches))\n",
    "            \n",
    "            # Drop 'win' for prediction and save 'win' for comparison\n",
    "            dataframe_predict = dataframe['ttlPings']\n",
    "            win_labels = dataframe['win']\n",
    "            # Reshape to 1-D array(column-vector)\n",
    "            x_data_features = np.array(dataframe_predict).reshape(-1,1)\n",
    "            \n",
    "            # Predict\n",
    "            prediction = mlp_classifier.predict(x_data_features)\n",
    "            prediction_proba = mlp_classifier.predict_proba(x_data_features)\n",
    "            score = mlp_classifier.score(x_data_features, win_labels)\n",
    "\n",
    "            # Save prediction results in dictionary\n",
    "            prediction_results = build_dictionary_prediction_results(prediction, prediction_proba, score)\n",
    "        # User Story 2/3, model kda for prediction\n",
    "        else:\n",
    "            # Load model\n",
    "            mlp_classifier = connector.load_model(\"kda\")\n",
    "            \n",
    "            dataframe_kda = build_dataframe_kda(list(matches))\n",
    "            \n",
    "            # Drop 'win' for prediction and save 'win' for comparison\n",
    "            win_labels = dataframe_kda['win']\n",
    "            x_data_features = dataframe_kda.drop(['win'], axis=1)\n",
    "    \n",
    "            # Predict\n",
    "            prediction = mlp_classifier.predict(x_data_features)\n",
    "            prediction_proba = mlp_classifier.predict_proba(x_data_features)\n",
    "            score = mlp_classifier.score(x_data_features, win_labels)\n",
    "\n",
    "            # Save prediction results in dictionary\n",
    "            prediction_results = build_dictionary_prediction_results(prediction, prediction_proba, score)\n",
    "    \n",
    "    return http_status, prediction_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f842d2815b7eda78dc85586fa9d618bca455650ef3ae1e10f7bd3f5a50f288bc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}